# -*- coding: utf-8 -*-
"""IncomeCode.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1dwSdQFje4P5F-sY9bFr6Uk2sPQOinGYR
"""

import pandas as pd

merged_data = pd.read_csv ("drive/MyDrive/Trenton MOVES/Trenton/merged_data.csv")
merged_data = merged_data.drop(columns = "Unnamed: 0")
merged_data['Person ID'] = merged_data['Person ID'].astype(int)
merged_data

unique = merged_data.drop_duplicates(subset = ["Person ID"])
unique = pd.DataFrame(unique)
unique

frequency = unique["HH ID"].value_counts()
frequency = pd.DataFrame(frequency)
frequency = frequency.reset_index(level=0)
frequency = frequency.sort_values(by=["index"])
frequency.rename(columns={'index': 'HH ID', "HH ID": "Household Size"}, inplace=True, errors='raise')
frequency

frequency['Household Size'] = pd.to_numeric(frequency['Household Size'],errors='coerce')
for i, row in enumerate (frequency.iloc[:,1]):
  c = 1
  while c < frequency.iloc[i,1]:
    new_row = frequency.iloc[i]
    frequency = frequency.append(new_row)
    c += 1
  if i == 63083:
    #The above number depends on the length of the df
    break

frequency = frequency.sort_values(by=["HH ID"])
unique = unique.sort_values(by=["HH ID"])
unique = unique.reset_index(drop=True)
frequency = frequency.reset_index(drop=True)

unique

frequency

unique_hh = pd.concat([unique, frequency], axis=1)
unique_hh

unique_hh.to_csv("drive/MyDrive/Trenton MOVES/Trenton/unique_hh.csv")

pd.set_option('display.max_columns', None)

unique_hh = pd.read_csv("drive/MyDrive/Trenton MOVES/Trenton/unique_hh.csv")
unique_hh
unique_hh = unique_hh.drop(columns = "Unnamed: 0")
unique_hh = unique_hh.drop(columns = "HH ID.1")
unique_hh = unique_hh.drop(columns = "Person ID.1")
unique_hh = unique_hh.drop(columns = "County Code.1")
unique_hh['Person ID'] = unique_hh['Person ID'].astype(int)
unique_hh

unique_hh = unique_hh.sort_values(by=["HH ID"])
unique_hh = unique_hh.append(pd.Series(), ignore_index=True)
unique_hh = unique_hh.append(pd.Series(), ignore_index=True)
unique_hh = unique_hh.append(pd.Series(), ignore_index=True)

unique_hh

lista = []
unique_hh['Income Amount'] = pd.to_numeric(unique_hh['Income Amount'],errors='coerce')
i = 0
for a, row in enumerate(unique_hh.iloc[:,22]):
  if i == 190735:
    #The above number depends on the length of the df
      break
  while a == i:
    c = 1
    sum = unique_hh.iloc[i,30]
    while row == unique_hh.iloc[i+c, 22]:
      sum = sum + unique_hh.iloc[i+c,30]
      c += 1
    f = 0
    while f < c:
      lista.append(sum)
      f += 1
    i = i + c

results = pd.DataFrame()
results["Cumulative Income"] = lista
results

unique_hh

unique_hh = unique_hh.drop(index=190735)
unique_hh = unique_hh.drop(index=190736)
unique_hh = unique_hh.drop(index=190737)

full_data = pd.concat([unique_hh, results], axis=1)
full_data.to_csv("drive/MyDrive/Trenton MOVES/Trenton/full_data")
#This dataset has the hh size and income accurate for every person and every trip but there is a mistake because trips are not accurately portrayed. That is why the following code is necessary

#EMPIEZA A PARTIR DE ACA

data = pd.read_csv("drive/MyDrive/Trenton MOVES/Trenton/full_data")
data = data.drop(columns = "Unnamed: 0")
data['Person ID'] = data['Person ID'].astype(int)
data

for row in data["Person ID"]:
  a = type(row)
  if type(row) != float:
    print("FUCK")

data

merged_data = pd.read_csv ("drive/MyDrive/Trenton MOVES/Trenton/merged_data.csv")
merged_data = merged_data.drop(columns = "Unnamed: 0")
merged_data['Person ID'] = merged_data['Person ID'].astype(int)
merged_data

frequency = merged_data["Person ID"].value_counts()
frequency = pd.DataFrame(frequency)
frequency = frequency.reset_index(level=0)
frequency = frequency.sort_values(by=["index"])
frequency

adjusted_data = pd.DataFrame()
for i, row in data.iterrows():
  c = 0
  while c < frequency.iloc[i,1]:
    adjusted_data = adjusted_data.append(row)
    c = c + 1

adjusted_data
adjusted_data.to_csv("drive/myDrive/Trenton MOVES/Trenton/adjusted_data.csv")

data = adjusted_data
columns = data.iloc[:,31:33]
columns =columns.reset_index(drop=True)
columns

dataset = pd.concat([merged_data, columns], axis =1)
dataset = dataset.drop(columns = "Person ID.1")
dataset = dataset.drop(columns = "County Code.1")
dataset.rename(columns={'Cumulative Income': 'Total Household Income'}, inplace=True, errors='raise')
dataset.to_csv("drive/MyDrive/Trenton MOVES/Trenton/dataset.csv")

dataset

data = pd.read_csv("drive/MyDrive/Trenton MOVES/Trenton/dataset.csv")
data = data.drop(columns = "Unnamed: 0")
data['Person ID'] = data['Person ID'].astype(int)
data['Total Household Income'] = data['Total Household Income'].astype(int)
data.sort_values(by=["Person ID"])
data

def poverty(x,y):
  a = (x * 4540) + 8320
  b = y
  if a < b:
    return ("False")
  else:
    return("True")

income = []
for i, person in enumerate(data.iloc[:,31]):
  x = data.iloc[i,31]
  y = data.iloc[i,32]
  income.append(poverty(x,y))
income

ipd = pd.DataFrame()
ipd["Poverty"] = income
data = pd.concat([data,ipd], axis=1)
data.to_csv("drive/MyDrive/Trenton MOVES/Trenton/incomedataset.csv")